export const translations = {
  en: {
    // App
    appTitle: "LLM Council",
    newConversation: "New Conversation",
    configuration: "Configuration",
    close: "Close",
    
    // Chat
    startConversation: "Start a conversation",
    askQuestion: "Ask a question to consult the LLM Council",
    askPlaceholder: "Ask your question... (Shift+Enter for new line, Enter to send)",
    send: "Send",
    you: "You",
    consultingCouncil: "Consulting the council...",
    
    // Stages
    stage1Title: "Stage 1: Individual Responses",
    stage2Title: "Stage 2: Peer Rankings",
    stage2Description: "Each model evaluated all responses (anonymized as Response A, B, C, etc.) and provided rankings. Below, model names are shown in bold for readability, but the original evaluation used anonymous labels.",
    stage2RawEvaluations: "Raw Evaluations",
    stage2AggregateRankings: "Aggregate Rankings (Street Cred)",
    stage2AggregateDescription: "Combined results across all peer evaluations (lower score is better):",
    stage2ExtractedRanking: "Extracted Ranking:",
    stage2_5Title: "Stage 2.5: Debate",
    stage2_5Description: "The models engage in a structured debate, responding to each other's arguments and refining their positions.",
    stage2_5Round: "Round",
    stage3Title: "Stage 3: Final Council Answer",
    stage3Chairman: "Chairman:",
    
    // Loading states
    loadingStage1: "Running Stage 1: Collecting individual responses...",
    loadingStage2: "Running Stage 2: Peer rankings...",
    loadingStage2_5: "Running Stage 2.5: Debate...",
    loadingStage3: "Running Stage 3: Final synthesis...",
    
    // Configuration
    configTitle: "Council Configuration",
    configProvider: "Provider:",
    configProviderOllama: "Ollama (Local)",
    configProviderOpenRouter: "OpenRouter (Cloud)",
    configProviderAuto: "Auto-detect",
    configAvailableModels: "Available Models",
    configRefresh: "üîÑ Refresh",
    configLoadingModels: "Loading models...",
    configNoModels: "No models available. Make sure Ollama is running or OpenRouter API key is configured.",
    configNumberModels: "Number of Models to Use:",
    configWillUse: "Will use all",
    configWillSelect: "Will randomly select",
    configFromSelected: "from",
    configSelectedModels: "selected models",
    configChairmanRandom: "Select Chairman randomly from models",
    configChairmanFirst: "First model will be used as Chairman",
    configApply: "Apply Configuration",
    configApplying: "Applying...",
    configSelected: "Selected:",
    configError: "Failed to load models:",
    configSuccess: "Configuration applied successfully",
    
    // Sidebar
    noConversations: "No conversations yet",
    messages: "messages",
  },
  
  fr: {
    // App
    appTitle: "Conseil LLM",
    newConversation: "Nouvelle Conversation",
    configuration: "Configuration",
    close: "Fermer",
    
    // Chat
    startConversation: "D√©marrer une conversation",
    askQuestion: "Posez une question pour consulter le Conseil LLM",
    askPlaceholder: "Posez votre question... (Shift+Entr√©e pour nouvelle ligne, Entr√©e pour envoyer)",
    send: "Envoyer",
    you: "Vous",
    consultingCouncil: "Consultation du conseil...",
    
    // Stages
    stage1Title: "√âtape 1 : R√©ponses Individuelles",
    stage2Title: "√âtape 2 : Classements par les Pairs",
    stage2Description: "Chaque mod√®le a √©valu√© toutes les r√©ponses (anonymis√©es comme R√©ponse A, B, C, etc.) et a fourni des classements. Ci-dessous, les noms des mod√®les sont affich√©s en gras pour la lisibilit√©, mais l'√©valuation originale utilisait des √©tiquettes anonymes.",
    stage2RawEvaluations: "√âvaluations Brutes",
    stage2AggregateRankings: "Classements Agr√©g√©s (Cr√©dibilit√©)",
    stage2AggregateDescription: "R√©sultats combin√©s de toutes les √©valuations par les pairs (score plus bas = meilleur) :",
    stage2ExtractedRanking: "Classement Extra√Æt :",
    stage2_5Title: "√âtape 2.5 : D√©bat",
    stage2_5Description: "Les mod√®les s'engagent dans un d√©bat structur√©, r√©pondant aux arguments des autres et affinant leurs positions.",
    stage2_5Round: "Tour",
    stage3Title: "√âtape 3 : R√©ponse Finale du Conseil",
    stage3Chairman: "Pr√©sident :",
    
    // Loading states
    loadingStage1: "Ex√©cution de l'√©tape 1 : Collecte des r√©ponses individuelles...",
    loadingStage2: "Ex√©cution de l'√©tape 2 : Classements par les pairs...",
    loadingStage2_5: "Ex√©cution de l'√©tape 2.5 : D√©bat...",
    loadingStage3: "Ex√©cution de l'√©tape 3 : Synth√®se finale...",
    
    // Configuration
    configTitle: "Configuration du Conseil",
    configProvider: "Fournisseur :",
    configProviderOllama: "Ollama (Local)",
    configProviderOpenRouter: "OpenRouter (Cloud)",
    configProviderAuto: "D√©tection automatique",
    configAvailableModels: "Mod√®les Disponibles",
    configRefresh: "üîÑ Actualiser",
    configLoadingModels: "Chargement des mod√®les...",
    configNoModels: "Aucun mod√®le disponible. Assurez-vous qu'Ollama est en cours d'ex√©cution ou que la cl√© API OpenRouter est configur√©e.",
    configNumberModels: "Nombre de Mod√®les √† Utiliser :",
    configWillUse: "Utilisera tous les",
    configWillSelect: "S√©lectionnera al√©atoirement",
    configFromSelected: "parmi les",
    configSelectedModels: "mod√®les s√©lectionn√©s",
    configChairmanRandom: "S√©lectionner le Pr√©sident al√©atoirement parmi les mod√®les",
    configChairmanFirst: "Le premier mod√®le sera utilis√© comme Pr√©sident",
    configApply: "Appliquer la Configuration",
    configApplying: "Application...",
    configSelected: "S√©lectionn√© :",
    configError: "√âchec du chargement des mod√®les :",
    configSuccess: "Configuration appliqu√©e avec succ√®s",
    
    // Sidebar
    noConversations: "Aucune conversation pour le moment",
    messages: "messages",
  },
  
  es: {
    // App
    appTitle: "Consejo LLM",
    newConversation: "Nueva Conversaci√≥n",
    configuration: "Configuraci√≥n",
    close: "Cerrar",
    
    // Chat
    startConversation: "Iniciar una conversaci√≥n",
    askQuestion: "Haz una pregunta para consultar al Consejo LLM",
    askPlaceholder: "Haz tu pregunta... (Shift+Enter para nueva l√≠nea, Enter para enviar)",
    send: "Enviar",
    you: "T√∫",
    consultingCouncil: "Consultando al consejo...",
    
    // Stages
    stage1Title: "Etapa 1: Respuestas Individuales",
    stage2Title: "Etapa 2: Clasificaciones por Pares",
    stage2Description: "Cada modelo evalu√≥ todas las respuestas (anonimizadas como Respuesta A, B, C, etc.) y proporcion√≥ clasificaciones. A continuaci√≥n, los nombres de los modelos se muestran en negrita para legibilidad, pero la evaluaci√≥n original us√≥ etiquetas an√≥nimas.",
    stage2RawEvaluations: "Evaluaciones en Bruto",
    stage2AggregateRankings: "Clasificaciones Agregadas (Cr√©dito)",
    stage2AggregateDescription: "Resultados combinados de todas las evaluaciones por pares (puntuaci√≥n m√°s baja = mejor):",
    stage2ExtractedRanking: "Clasificaci√≥n Extra√≠da:",
    stage2_5Title: "Etapa 2.5: Debate",
    stage2_5Description: "Los modelos participan en un debate estructurado, respondiendo a los argumentos de los dem√°s y refinando sus posiciones.",
    stage2_5Round: "Ronda",
    stage3Title: "Etapa 3: Respuesta Final del Consejo",
    stage3Chairman: "Presidente:",
    
    // Loading states
    loadingStage1: "Ejecutando Etapa 1: Recopilando respuestas individuales...",
    loadingStage2: "Ejecutando Etapa 2: Clasificaciones por pares...",
    loadingStage2_5: "Ejecutando Etapa 2.5: Debate...",
    loadingStage3: "Ejecutando Etapa 3: S√≠ntesis final...",
    
    // Configuration
    configTitle: "Configuraci√≥n del Consejo",
    configProvider: "Proveedor:",
    configProviderOllama: "Ollama (Local)",
    configProviderOpenRouter: "OpenRouter (Nube)",
    configProviderAuto: "Detecci√≥n autom√°tica",
    configAvailableModels: "Modelos Disponibles",
    configRefresh: "üîÑ Actualizar",
    configLoadingModels: "Cargando modelos...",
    configNoModels: "No hay modelos disponibles. Aseg√∫rate de que Ollama est√© en ejecuci√≥n o que la clave API de OpenRouter est√© configurada.",
    configNumberModels: "N√∫mero de Modelos a Usar:",
    configWillUse: "Usar√° todos los",
    configWillSelect: "Seleccionar√° aleatoriamente",
    configFromSelected: "de los",
    configSelectedModels: "modelos seleccionados",
    configChairmanRandom: "Seleccionar Presidente aleatoriamente de los modelos",
    configChairmanFirst: "El primer modelo se usar√° como Presidente",
    configApply: "Aplicar Configuraci√≥n",
    configApplying: "Aplicando...",
    configSelected: "Seleccionado:",
    configError: "Error al cargar modelos:",
    configSuccess: "Configuraci√≥n aplicada exitosamente",
    
    // Sidebar
    noConversations: "A√∫n no hay conversaciones",
    messages: "mensajes",
  },
  
  de: {
    // App
    appTitle: "LLM-Rat",
    newConversation: "Neue Unterhaltung",
    configuration: "Konfiguration",
    close: "Schlie√üen",
    
    // Chat
    startConversation: "Eine Unterhaltung beginnen",
    askQuestion: "Stellen Sie eine Frage, um den LLM-Rat zu konsultieren",
    askPlaceholder: "Stellen Sie Ihre Frage... (Shift+Enter f√ºr neue Zeile, Enter zum Senden)",
    send: "Senden",
    you: "Sie",
    consultingCouncil: "Rat wird konsultiert...",
    
    // Stages
    stage1Title: "Stufe 1: Individuelle Antworten",
    stage2Title: "Stufe 2: Peer-Bewertungen",
    stage2Description: "Jedes Modell bewertete alle Antworten (anonymisiert als Antwort A, B, C usw.) und lieferte Bewertungen. Unten sind Modellnamen zur Lesbarkeit fett dargestellt, aber die urspr√ºngliche Bewertung verwendete anonyme Labels.",
    stage2RawEvaluations: "Rohe Bewertungen",
    stage2AggregateRankings: "Aggregierte Bewertungen (Glaubw√ºrdigkeit)",
    stage2AggregateDescription: "Kombinierte Ergebnisse aller Peer-Bewertungen (niedrigere Punktzahl = besser):",
    stage2ExtractedRanking: "Extrahierte Bewertung:",
    stage2_5Title: "Stufe 2.5: Debatte",
    stage2_5Description: "Die Modelle f√ºhren eine strukturierte Debatte, reagieren auf die Argumente der anderen und verfeinern ihre Positionen.",
    stage2_5Round: "Runde",
    stage3Title: "Stufe 3: Finale Rat-Antwort",
    stage3Chairman: "Vorsitzender:",
    
    // Loading states
    loadingStage1: "Stufe 1 wird ausgef√ºhrt: Sammeln individueller Antworten...",
    loadingStage2: "Stufe 2 wird ausgef√ºhrt: Peer-Bewertungen...",
    loadingStage2_5: "Stufe 2.5 wird ausgef√ºhrt: Debatte...",
    loadingStage3: "Stufe 3 wird ausgef√ºhrt: Finale Synthese...",
    
    // Configuration
    configTitle: "Rat-Konfiguration",
    configProvider: "Anbieter:",
    configProviderOllama: "Ollama (Lokal)",
    configProviderOpenRouter: "OpenRouter (Cloud)",
    configProviderAuto: "Auto-Erkennung",
    configAvailableModels: "Verf√ºgbare Modelle",
    configRefresh: "üîÑ Aktualisieren",
    configLoadingModels: "Modelle werden geladen...",
    configNoModels: "Keine Modelle verf√ºgbar. Stellen Sie sicher, dass Ollama l√§uft oder der OpenRouter API-Schl√ºssel konfiguriert ist.",
    configNumberModels: "Anzahl der zu verwendenden Modelle:",
    configWillUse: "Verwendet alle",
    configWillSelect: "W√§hlt zuf√§llig",
    configFromSelected: "aus den",
    configSelectedModels: "ausgew√§hlten Modellen",
    configChairmanRandom: "Vorsitzenden zuf√§llig aus Modellen ausw√§hlen",
    configChairmanFirst: "Das erste Modell wird als Vorsitzender verwendet",
    configApply: "Konfiguration Anwenden",
    configApplying: "Wird angewendet...",
    configSelected: "Ausgew√§hlt:",
    configError: "Fehler beim Laden der Modelle:",
    configSuccess: "Konfiguration erfolgreich angewendet",
    
    // Sidebar
    noConversations: "Noch keine Unterhaltungen",
    messages: "Nachrichten",
  },
};

export const languages = [
  { code: 'en', name: 'English', flag: 'üá¨üáß' },
  { code: 'fr', name: 'Fran√ßais', flag: 'üá´üá∑' },
  { code: 'es', name: 'Espa√±ol', flag: 'üá™üá∏' },
  { code: 'de', name: 'Deutsch', flag: 'üá©üá™' },
];

export const defaultLanguage = 'en';

